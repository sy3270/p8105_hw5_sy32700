p8105_hw5_sy3270.Rmd
================
2024-11-06

# Problem 1

``` r
check_shared_birthday <- function(group_size) {
  birthdays <- sample(1:365, group_size, replace = TRUE)
  any(duplicated(birthdays))
}

set.seed(123) 
results <- map_df(2:50, function(n) {
  simulations <- replicate(10000, check_shared_birthday(n))
  prob <- mean(simulations)
  tibble(group_size = n, probability = prob)
})

ggplot(results, aes(x = group_size, y = probability)) +
  geom_line() +
  labs(
    title = "Probability of Shared Birthday vs Group Size",
    x = "Group Size",
    y = "Probability of Shared Birthday"
  ) +
  theme_minimal()
```

![](p8105_hm5_sy3270_files/figure-gfm/unnamed-chunk-1-1.png)<!-- -->

This plot shows the probability of at least two people sharing a
birthday as a function of group size, ranging from 2 to 50. As the group
size increases, the probability of a shared birthday rises
significantly, demonstrating the well-known “birthday paradox.” Even
with a relatively small group size (e.g., around 23), the probability
approaches 50%, and by around 50 people, the probability is almost
certain. This result highlights how counterintuitive probabilities can
be in situations involving shared events.

# Problem 2

``` r
n <- 30
sigma <- 5
alpha <- 0.05


run_power_simulation <- function(mu) {
  simulations <- replicate(5000, {
    data <- rnorm(n, mean = mu, sd = sigma)
    test_result <- t.test(data, mu = 0)
    data.frame(mu_hat = test_result$estimate, p_value = test_result$p.value)
  }, simplify = FALSE)
  
  simulations_df <- do.call(rbind, simulations)
  simulations_df$rejected <- simulations_df$p_value < alpha
  return(simulations_df)
}


mu_values <- 1:6
results_list <- lapply(mu_values, function(mu) {
  sim_data <- run_power_simulation(mu)
  power <- mean(sim_data$rejected)
  mu_hat_mean <- mean(sim_data$mu_hat[sim_data$rejected])
  data.frame(mu = mu, power = power, mu_hat_mean = mu_hat_mean)
})


results <- do.call(rbind, results_list)


library(ggplot2)
power_plot <- ggplot(results, aes(x = mu, y = power)) +
  geom_line() +
  labs(
    title = "Power of One-Sample t-Test vs Effect Size",
    x = "Effect Size (True Mean)",
    y = "Power"
  ) +
  theme_minimal()

print(power_plot)
```

![](p8105_hm5_sy3270_files/figure-gfm/design%20analysis-1.png)<!-- -->

``` r
mu_hat_plot <- ggplot(results, aes(x = mu, y = mu_hat_mean)) +
  geom_line() +
  labs(
    title = "Estimated Mean for Rejected Tests vs True Mean",
    x = "True Mean (Effect Size)",
    y = "Mean of Estimated Mean for Rejected Tests"
  ) +
  theme_minimal()


print(mu_hat_plot)
```

![](p8105_hm5_sy3270_files/figure-gfm/design%20analysis-2.png)<!-- -->

Power vs. Effect Size Plot: This plot shows that as the true mean
(effect size) increases, the power of the t-test (likelihood of
detecting a true effect) also increases. Larger effect sizes make it
easier to reject the null hypothesis.

Mean of Estimated Means for Rejected Tests Plot: This plot indicates
that for tests where the null hypothesis was rejected, the estimated
mean closely aligns with the true mean, showing that the t-test provides
an accurate effect estimate when it detects a significant difference.

# Problem 3

The raw data contains information on homicides in major U.S. cities,
including details on the victim, location, and case disposition; a new
city_state variable was created to group data by city and state,
summarizing the total number of homicides and unsolved cases where the
disposition was “Closed without arrest” or “Open/No arrest.”

``` r
homicide_data <- read.csv("./homicide-data.csv", stringsAsFactors = FALSE)

homicide_data$city_state <- paste(homicide_data$city, homicide_data$state, sep = ", ")
homicide_data$unsolved <- homicide_data$disposition %in% c("Closed without arrest", "Open/No arrest")

city_summary <- group_by(homicide_data, city_state)
city_summary <- summarize(city_summary,
                          total_homicides = n(),
                          unsolved_homicides = sum(unsolved))
city_summary <- mutate(city_summary,
                       unsolved_proportion = unsolved_homicides / total_homicides)

baltimore_data <- filter(city_summary, city_state == "Baltimore, MD")

baltimore_test <- prop.test(x = baltimore_data$unsolved_homicides,
                            n = baltimore_data$total_homicides)

baltimore_result <- tidy(baltimore_test)

prop_test_results <- vector("list", nrow(city_summary))
tidy_results <- vector("list", nrow(city_summary))

for (i in seq_len(nrow(city_summary))) {
  test <- prop.test(x = city_summary$unsolved_homicides[i],
                    n = city_summary$total_homicides[i])
  prop_test_results[[i]] <- test
  tidy_results[[i]] <- tidy(test)
}
```

    ## Warning in prop.test(x = city_summary$unsolved_homicides[i], n =
    ## city_summary$total_homicides[i]): Chi-squared approximation may be incorrect

``` r
tidy_results_df <- bind_rows(tidy_results)
city_test_results <- cbind(city_summary, tidy_results_df)

plot <- ggplot(city_test_results, aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.3) +
  coord_flip() +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Proportion of Unsolved Homicides",
    caption = "Data Source: Washington Post"
  ) +
  theme_minimal()

print(plot)
```

![](p8105_hm5_sy3270_files/figure-gfm/homicide-1.png)<!-- -->

The analysis showed significant variation in unsolved homicide rates
across major U.S. cities, with Baltimore, MD, having one of the highest
proportions at 64.6%. Confidence intervals from the proportion tests
provided a measure of uncertainty, highlighting variability in
resolution rates among cities. The chi-squared approximation warning in
prop.test suggests that results may be less reliable for cities with
small sample sizes, which should be considered when interpreting the
confidence intervals for those cities.
